import os
import joblib
import numpy as np
import pandas as pd
import psycopg2
import tensorflow as tf
from datetime import datetime, timedelta

DB_HOST = os.getenv("DB_HOST")
DB_NAME = os.getenv("DB_NAME")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS")

BASE_DIR = os.environ.get('LAMBDA_TASK_ROOT', '')
MODEL_PATH = os.path.join(BASE_DIR, 'models', 'solar_mlp.keras')
SCALER_PATH = os.path.join(BASE_DIR, 'models', 'scaler.pkl')

model = None
scaler = None

print("‚è≥ Initializing Prediction Service...")
try:
    # Load model Keras (ch·ªâ load 1 l·∫ßn
    model = tf.keras.models.load_model(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    print("‚úÖ Model & Scaler loaded successfully.")
except Exception as e:
    print(f"‚ö†Ô∏è CRITICAL: Could not load model/scaler: {e}")

def get_db_connection():
    return psycopg2.connect(
        host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASS
    )

def fetch_recent_data():
    """
    L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ t√≠nh to√°n features (Lag, Trend...).
    C·∫ßn l·∫•y d∆∞ ra (v√≠ d·ª• 100 d√≤ng) ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh ƒë·ªß Lag 24h.
    """
    query = """
        SELECT datetime, solar_mw, solar_trend, solar_seasonal, solar_normalized 
        FROM electricity_analysis_results
        ORDER BY datetime DESC LIMIT 100
    """
    try:
        conn = get_db_connection()
        df = pd.read_sql(query, conn)
        conn.close()
        # ƒê·∫£o ng∆∞·ª£c l·∫°i ƒë·ªÉ c√≥ th·ª© t·ª± th·ªùi gian tƒÉng d·∫ßn (C≈© -> M·ªõi)
        return df.iloc[::-1].reset_index(drop=True)
    except Exception as e:
        print(f"‚ùå DB Error: {e}")
        return pd.DataFrame()

def prepare_features(df):
    """
    T·∫°o input vector (1, 7) cho Model.
    Th·ª© t·ª± feature ph·∫£i KH·ªöP 100% v·ªõi l√∫c train.
    """
    if len(df) < 25:
        print("‚ö†Ô∏è Not enough data history.")
        return None, None

    df['datetime'] = pd.to_datetime(df['datetime'])
    
    # Feature Engineering
    df['solar_mw_lag1'] = df['solar_mw'].shift(1)
    df['solar_mw_lag24'] = df['solar_mw'].shift(24)
    df['hour'] = df['datetime'].dt.hour
    df['day_of_week'] = df['datetime'].dt.dayofweek
    
    # L·∫•y d√≤ng cu·ªëi c√πng (Latest) h·ª£p l·ªá
    valid_df = df.dropna().tail(1)
    
    if valid_df.empty:
        return None, None
        
    latest = valid_df.iloc[0]
    current_time = latest['datetime']
    
    # T·∫°o vector input chu·∫©n (1, 7)
    # Th·ª© t·ª±: [Norm, Trend, Seasonal, Hour, Day, Lag1, Lag24]
    features = np.array([
        latest['solar_normalized'], 
        latest['solar_trend'],      
        latest['solar_seasonal'],   
        latest['hour'],             
        latest['day_of_week'],      
        latest['solar_mw_lag1'],    
        latest['solar_mw_lag24']    
    ]).reshape(1, -1)
    
    return features, current_time

def save_predictions(predictions, start_time):
    """L∆∞u k·∫øt qu·∫£ d·ª± b√°o 24h v√†o DB"""
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # T·∫°o b·∫£ng prediction n·∫øu ch∆∞a c√≥
        cur.execute("""
            CREATE TABLE IF NOT EXISTS solar_predictions (
                id SERIAL PRIMARY KEY,
                prediction_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                target_time TIMESTAMP,
                predicted_solar_mw FLOAT,
                created_at TIMESTAMP DEFAULT NOW()
            )
        """)
        
        values = []
        for i, val in enumerate(predictions):
            target_time = start_time + timedelta(hours=i + 1)
            val_mw = max(float(val), 0.0) # Kh√¥ng l·∫•y s·ªë √¢m
            values.append((target_time, val_mw))
        
        # Batch Insert
        args_str = ','.join(cur.mogrify("(NOW(), %s, %s)", x).decode('utf-8') for x in values)
        cur.execute("INSERT INTO solar_predictions (prediction_time, target_time, predicted_solar_mw) VALUES " + args_str)
        
        conn.commit()
        cur.close()
        conn.close()
        print(f"‚úÖ Saved predictions for next 24 hours.")
    except Exception as e:
        print(f"‚ùå Save Error: {e}")

def run_prediction_job():
    print(f"--- Starting Prediction Job: {datetime.now()} ---")
    
    if model is None:
        print("‚ùå Model is NOT loaded. Cannot predict.")
        return False

    # 1. Fetch Data
    df = fetch_recent_data()
    if df.empty: return False

    # 2. Prepare Features
    X_input, current_time = prepare_features(df)
    if X_input is None: 
        print("‚ö†Ô∏è Not enough valid data for feature engineering.")
        return False

    # 3. Predict using TensorFlow Model
    try:
        print(f"üîÆ Predicting for time > {current_time}...")
        # Model tr·∫£ v·ªÅ (1, 24) -> flatten th√†nh (24,)
        preds = model.predict(X_input, verbose=0).flatten()
        
        save_predictions(preds, current_time)
        return True
    except Exception as e:
        print(f"‚ùå Prediction Logic Error: {e}")
        return False