import os
import pandas as pd
from sqlalchemy import create_engine, text
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# --- C·∫§U H√åNH ENVIRONMENT ---
DB_HOST = os.getenv("DB_HOST")
DB_NAME = os.getenv("DB_NAME")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS")

# Connection String
DB_URL = f"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:5432/{DB_NAME}"

def get_db_engine():
    return create_engine(DB_URL)

def bulk_update_db(engine, df, table_name, key_column, target_column='cluster_id'):
    """
    K·ªπ thu·∫≠t Bulk Update: T·∫°o b·∫£ng t·∫°m -> Insert -> Update -> Drop.
    Nhanh g·∫•p 100 l·∫ßn so v·ªõi Update t·ª´ng d√≤ng.
    """
    if df.empty: return 0
    
    temp_table = f"temp_{table_name}_clusters"
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu update
    update_df = df[[key_column, target_column]].copy()
    if 'datetime' in key_column:
        update_df[key_column] = update_df[key_column].astype(str)

    with engine.connect() as conn:
        trans = conn.begin()
        try:
            # 1. T·∫°o b·∫£ng t·∫°m & Insert
            update_df.to_sql(temp_table, conn, if_exists='replace', index=False)
            
            # 2. Update t·ª´ b·∫£ng t·∫°m sang b·∫£ng ch√≠nh
            if key_column == 'datetime':
                where_clause = f"main.{key_column}::text = temp.{key_column}"
            else:
                where_clause = f"main.{key_column} = temp.{key_column}"

            # C·∫ßn ƒë·∫£m b·∫£o c·ªôt cluster_id t·ªìn t·∫°i trong b·∫£ng ch√≠nh tr∆∞·ªõc
            # (Th∆∞·ªùng DB Admin ph·∫£i alter table add column cluster_id int tr∆∞·ªõc)
            
            sql = text(f"""
                UPDATE {table_name} AS main
                SET {target_column} = temp.{target_column}
                FROM {temp_table} AS temp
                WHERE {where_clause};
            """)
            
            result = conn.execute(sql)
            
            # 3. D·ªçn d·∫πp
            conn.execute(text(f"DROP TABLE IF EXISTS {temp_table}"))
            trans.commit()
            return result.rowcount
        except Exception as e:
            trans.rollback()
            print(f"‚ùå Bulk Update Error: {e}")
            raise e

def process_measurements_clustering(engine):
    print("üîπ Running Measurements Clustering...")
    try:
        # 1. Load Data
        query = "SELECT datetime, solar_mw, wind_mw, gas_mw, carbon_intensity FROM electricity_measurements"
        df = pd.read_sql(query, engine)
        
        if df.empty:
            print("‚ö†Ô∏è No measurements data found.")
            return
            
        # 2. Preprocessing
        features = ['solar_mw', 'wind_mw', 'gas_mw', 'carbon_intensity']
        X = df[features].fillna(0)
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # 3. K-Means
        kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')
        df['cluster_id'] = kmeans.fit_predict(X_scaled)

        # 4. Save to DB
        updated = bulk_update_db(engine, df, 'electricity_measurements', 'datetime')
        print(f"‚úÖ Measurements: Updated {updated} rows.")
        return True
    except Exception as e:
        print(f"‚ùå Error in Measurements Clustering: {e}")
        return False

def process_predictions_clustering(engine):
    print("üîπ Running Predictions Clustering...")
    try:
        # 1. Load Data
        # C·∫ßn check xem b·∫£ng c√≥ t·ªìn t·∫°i kh√¥ng ƒë·ªÉ tr√°nh l·ªói crash
        try:
            query = "SELECT id, predicted_solar_mw FROM solar_predictions"
            df = pd.read_sql(query, engine)
        except Exception:
            print("‚ö†Ô∏è Table 'solar_predictions' does not exist yet.")
            return

        if df.empty:
            print("‚ö†Ô∏è No prediction data found.")
            return

        # 2. Preprocessing
        X = df[['predicted_solar_mw']].fillna(0)
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # 3. K-Means
        kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')
        df['cluster_id'] = kmeans.fit_predict(X_scaled)

        # 4. Save to DB
        updated = bulk_update_db(engine, df, 'solar_predictions', 'id')
        print(f"‚úÖ Predictions: Updated {updated} rows.")
        return True
    except Exception as e:
        print(f"‚ùå Error in Predictions Clustering: {e}")
        return False

def run_clustering_job():
    print("--- Starting Clustering Job ---")
    try:
        engine = get_db_engine()
        
        # Ch·∫°y tu·∫ßn t·ª± 2 task
        task1 = process_measurements_clustering(engine)
        task2 = process_predictions_clustering(engine)
        
        engine.dispose()
        
        if task1 or task2:
            return True
        else:
            return False
            
    except Exception as e:
        print(f"‚ùå Critical Job Error: {e}")
        return False